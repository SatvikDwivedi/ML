# -*- coding: utf-8 -*-
"""Project_ML_Student_Satisfaction_Survey_RA_162_RA_140.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DFuw9-MoAsG0XfAFSSSto7cQnXR7bDnG
"""

#Importing the libraries

import pandas as pd  #Data manipulation
import numpy as np   #Data manipulation
import matplotlib.pyplot as plt  # Visualization
import seaborn as sb  # Visualization
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.metrics import accuracy_score,auc, roc_curve
from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix

#Loading the dataset collected from the google form into an excel sheet
df=pd.read_csv('/content/SRM Student Academic Satisfaction Survey (Responses).csv')

#Lets look into top few rows and columns in the dataset
df.head(5)

#Pre-Processing of the data
#1) To check whether there is missing values or not in the data
df.isnull().sum()

#2) Removing redundant features by keeping the numeric data only
df2=df.select_dtypes(include=[np.number])
df2.head(5)

#3) Checking for Outlier if any
for i in df2.columns:
    sb.boxplot(x=df2[i])
    plt.show()

#4)Outlier removal by dropping the outlier
for i in df2.columns: 
     q1=df2[i].quantile(0.25)
     q3=df2[i].quantile(0.75)
     iqr=q3-q1
     ub=q3+1.5*iqr
     lb=q1-1.5*iqr
     df3=df2[((df2[i]<ub) & (df2[i]>lb))]
     sb.boxplot(x=df3[i])
     plt.show()

#The correlation matrix is displayed below
corr_matrix=df.corr()
sb.heatmap(corr_matrix,annot=True)
plt.show()

#Training the Model

#Splitting the data into training and testing data

x_train,x_test,y_train,y_test=train_test_split(df3.drop('Rate Overall Satisfaction',axis=1),df3['Rate Overall Satisfaction'],test_size=0.20,random_state=42)

#The KNN model
from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier()
knn.fit(x_train,y_train)
predictknn=knn.predict(x_test)
accuracyknn=accuracy_score(y_test,predictknn)
print('\nThe Accuracy of the KNN model is :',round(accuracyknn*100,2),'%\n')
cm=confusion_matrix(y_test,predictknn)
cm_display=ConfusionMatrixDisplay(confusion_matrix=cm)
cm_display.plot()
plt.show()

#The Decision Tree Classifier model
from sklearn.tree import DecisionTreeClassifier
treemodel=DecisionTreeClassifier()
treemodel.fit(x_train,y_train)
predicttree=treemodel.predict(x_test)
accuracytree=accuracy_score(y_test,predicttree)
print('\nThe Accuracy of the Decision Tree Classifier model is :',round(accuracytree*100,2),'%\n')
cm=confusion_matrix(y_test,predicttree)
cm_display=ConfusionMatrixDisplay(confusion_matrix=cm)
cm_display.plot()
plt.show()

#The Random Forest Classifier
from  sklearn.ensemble import RandomForestClassifier
random=RandomForestClassifier()
random.fit(x_train,y_train)
predictrandom=random.predict(x_test)
accuracyrandom=accuracy_score(y_test,predictrandom)
print('\nThe Accuracy of the Random Forest Classifier model is :',round(accuracyrandom*100,2),'%\n')
cm=confusion_matrix(y_test,predictrandom)
cm_display=ConfusionMatrixDisplay(confusion_matrix=cm)
cm_display.plot()
plt.show()

#The Naive Bayes
from sklearn.naive_bayes import GaussianNB
nb=GaussianNB()
nb.fit(x_train,y_train)
predictnb=nb.predict(x_test)
accuracynb=accuracy_score(y_test,predictnb)
print('\nThe Accuracy of the Naive Bayes model is :',round(accuracynb*100,2),'%\n')
cm=confusion_matrix(y_test,predictnb)
cm_display=ConfusionMatrixDisplay(confusion_matrix=cm)
cm_display.plot()
plt.show()

# The SVM model
from sklearn import svm
SVM=svm.SVC()
SVM.fit(x_train,y_train)
predictsvm=SVM.predict(x_test)
accuracy=accuracy_score(y_test,predictsvm)
print('\nThe Accuracy of the SVM  model is : ',round(accuracy*100,2),'%\n')
cm=confusion_matrix(y_test,predictsvm)
cm_display=ConfusionMatrixDisplay(confusion_matrix=cm)
cm_display.plot()
plt.show()

#From the above given analysis we get that the best model are Random Forest Classifier and Decision Tree Classifier with both having an accuracy rate of 98.82% 
#which surpasses the SVM model with 86.39% , KNN model with 94.08% and Navie Bayes model with 77.51%.
#Making the Random Forest Classifier and Decision Tree Classifier as the best model to opt to calculate the accuracy with best result.







